## TCP头部描述

![[TCP_header.webp]]

### **序列号**

在建立连接时，由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机。每发送一次数据，就“**累加**”一次该“数据字节数”的大小。
> **作用**：用来**解决网络包乱序问题**。


### **确认应答号**

指下一次“**期望**”收到的数据的序列号。发送端收到这个确认应答号后，可以认为在这个序号之前的数据已经被正确接收。
> **作用**：用来**解决丢包的问题**。
### **控制位**

- **ACK**：该位为 `1` 时，“确认应答”字段变为有效。TCP 规定在最初建立连接时的 SYN 包之外，该位必须被置为 `1`。
- **RST**：该位为 `1` 时，表示 TCP 连接中出现异常，必须强制断开连接。
- **SYN**：该位为 `1` 时，表示希望建立连接，并在“序列号”字段进行初始值的设定。
- **FIN**：该位为 `1` 时，表示不会再有数据发送，希望断开连接。当通信结束，某一方希望断开连接时，通信双方的主机之间就会相互交换 `FIN` 置为 `1` 的 TCP 段。


---


## TCP 三次握手
![[TCP_three_times.webp]]

- 一开始，客户端和服务端都处于CLOSE状态。先是服务端主动监听某个端口，处于LISTEN状态


![[TCP_first.webp]]

-第一次握手： 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 头部的“序号”字段中，同时把 `SYN` 标志位置为 `1`，表示 `SYN` 报文。 接着把第一个 `SYN` 报文发送给服务器，表示向服务器发起连接。该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。


![[tcp_second.webp]]
- 第二次握手：服务器收到客户端的 `SYN` 报文后，首先服务器也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 头部的“序号”字段中。其次把 TCP 头部的“确认应答号”字段填入 `client_isn + 1`，接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发送给客户端，该报文也不包含应用层数据，之后服务器处于 `SYN-RCVD` 状态。


![[tcp_third.webp]]
-  第三次握手：客户端收到服务器报文后，还要向服务器回应最后一个应答报文。首先该应答报文 TCP 头部 `ACK` 标志位置为 `1`，其次“确认应答号”字段填入 `server_isn + 1`。最后把报文发送给服务器，该报文可以携带客户端到服务器的数据，之后客户端处于 `ESTABLISHED` 状态。服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

<span style="color: blue;">第三次握手是可以携带数据的，而前两次握手不可以携带数据</span>

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接建立完成，客户端和服务器就可以相互发送数据了。


---


## TCP为什么需要三次握手建立连接
三次握手的原因：
- <span style="color: blue;">三次握手才可以阻止重复历史连接的初始化（主要原因）</span>
- 三次握手才可以同步双方的初始序列号
- 三次握手才可以避免资源浪费

### 原因一：避免历史连接

我们考虑一个场景，客户端先发送了 `SYN (seq = 90)` 报文，然后客户端宕机了，而这个 `SYN` 报文还被网络阻塞，服务器并没有收到。
接着客户端重启后，又重新向服务器建立连接，发送了 `SYN (seq = 100)` 报文。
> **注意！这并不是重传 SYN，而是新的 SYN，重传的 SYN 的序列号是一样的。**

![[avoid_history_link.webp]]

在网络拥堵情况下：
- 一个“旧 SYN 报文”比“最新的 SYN”报文更早到达服务器，服务器会回复 `SYN + ACK` 报文，确认号为 `91 (90+1)`。
- 客户端收到后，发现自己期望收到的确认号应该是 `100+1`，而不是 `90+1`，于是会回复 `RST` 报文。
- 服务器收到 `RST` 报文后，终止连接。
- 客户端重新发送最新的 `SYN` 报文，服务器可以完成三次握手。

上述的“旧 SYN 报文”称为**历史连接**。TCP 使用三次握手的主要原因之一就是为了防止历史连接初始化。

> **如果是两次握手连接，就无法阻止历史连接。**

两次握手无法阻止历史连接的原因是：
- 服务器收到 `SYN` 报文后，就进入 `ESTABLISHED` 状态，意味着可以开始数据传输。
- 如果此时的 `SYN` 报文是历史连接，而客户端已经进入 `ESTABLISHED` 状态，客户端无法判断连接是否有效，导致服务器可能建立一个无效连接，浪费资源。
- 但在三次握手的情况下，客户端必须先收到服务器的 `SYN + ACK` 并回应 `ACK`，这样可以有效防止历史连接问题。


### 原因二：同步双方初始序列号
TCP 协议的通信双方，都必须维护一个“序列号”，序列号是可靠传输的一个关键因素，它的作用：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号按序接收；
- 可以标识发送出去的数据包中，哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）。

可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带“初始序列号”的 SYN 报文时，需要服务器回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务器成功接收。当服务器发送“初始序列号”给客户端时，依然也要等待客户端的应答返回。
**这样一来一回，才能确保双方的初始序列号能被可靠同步。**


### **原因三：避免资源浪费**

如果只有“两次握手”，当客户端发送的 SYN 报文在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN。由于没有第三次握手，**服务器不清楚客户端是否收到了自己回复的 ACK 报文**，所以服务器端每收到一个 SYN 就只能先主动建立一个连接。

如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费**。


---


# TCP 三次握手，客户端第三次发送的确认包丢失了会发生什么？

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。


![[miss_third_ack.webp]]




## 三次握手和accept是什么关系？accept做了哪些事情

TCP 完成三次握手后，连接会被保存到内核的全连接队列，调用 `accept` 就是从 **把连接取出来给用户程序使用**。

![[tcp_and_accept.webp]]



---

###  **`accept()` 的作用**

`accept()` 是 **服务器端** 在 **TCP 连接建立完成后** 用于 **提取已完成的连接** 的系统调用，它的作用是：
1. **从内核的全连接队列（Completed Connection Queue）中取出一个已完成的连接**，并返回一个新的 **已连接套接字（socket）**。
2. **让用户进程能够与客户端正式建立连接并进行数据收发**。
3. **处理新的客户端连接请求**，是 TCP 服务器并发模型的核心函数。


---

## 客户端发送的第一个 SYN 报文，服务器没有收到怎么办？

当客户端想和服务器建立 TCP 连接时的第一步，首先会发送一个 SYN 报文，然后进入到 SYN_SENT 状态。

在这之后，如果客户端迟迟收不到服务器的 SYN-ACK 报文（第二次握手），就会触发“**超时重传**”机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。

不同版本的操作系统可能超时的时间不同，有的 1 秒钟，也有 3 秒的，这个超时时间是写死在内核里的，如果想要更改则需要重新编译内核，比较麻烦。

当客户端在 1 秒后没收到服务器的 SYN-ACK 报文后，客户端就会重发 SYN 报文，那么到底发几次呢？

在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries` 内核参数控制，这个参数可以自定义，默认值一般是 5。

通常，第一次超时重传是 1 秒后，第二次超时重传是 2 秒，第三次超时重传是 4 秒，第四次超时重传是 8 秒， 第五次是超时重传 16 秒后。没有错，**每次超时的时间是上一次的 2 倍**。

当第 5 次超时重传后，会继续等待 32 秒，如果服务器仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。

所以，总耗时 = 1 + 2 + 4 + 8 + 16 + 32 = 63 秒，大约 1 分钟左右。

举个例子，假设 `tcp_syn_retries` 参数值为 3，那么当客户端的 SYN 报文一直在网络中丢失时，会发生如下的过程：


---


## 服务器收到第一个 SYN 报文，回复的 SYN + ACK 报文丢失了怎么办？

当服务器端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务器会进入 SYN_RCVD 状态。

第二次握手的 SYN-ACK 报文其实有两个目的：
- 第二次握手里的 ACK，是对第一次握手的确认报文；
- 第二次握手里的 SYN，是服务器发起建立 TCP 连接的报文。

所以，如果第二次握手丢了，就会发生比较有意思的事情，具体会怎么样呢？

因为第二次握手报文里包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得自己的 SYN 报文（第一次握手）丢失了，于是**客户端就会触发超时重传机制，重传 SYN 报文**。

然而，因为第二次握手中包含服务器的 SYN 报文，所以当客户端收到后，需要给服务器发送 ACK 确认报文（第三次握手），服务器端会认为这次 SYN 报文被客户端收到了。

那么，如果第二次握手丢失了，服务器端收不到第三次握手，**于是服务器这边会触发超时重传机制，重传 SYN-ACK 报文**。

因此，当第二次握手丢失了，<span style="color: blue;">客户端和服务器都会重传</span>：
- **客户端会重传 SYN 报文**，也就是第一次握手，最大重传次数由 `tcp_syn_retries` 内核参数决定；
- **服务器会重传 SYN-ACK 报文**，也就是第二次握手，最大重传次数由 `tcp_synack_retries` 内核参数决定。

举个例子，假设 `tcp_syn_retries` 参数值为 1，`tcp_synack_retries` 参数值为 2，那么当第二次握手一直丢失时，发生的过程如下图：


![[tcp_second_lost.webp]]


---


## 大量 SYN 包泛滥给服务器端会发生什么事情？

有可能会导致 TCP 半连接队列满了，这样**当 TCP 半连接队列满了，后续再收到 SYN 报文就会丢弃**，导致客户端和服务器端无法建立连接。

### 避免 SYN 攻击的方式

可以有以下四种方法：

- 调大 `netdev_max_backlog`；
- 增大 TCP 半连接队列；
- 开启 `tcp_syncookies`；
- 减少 SYN+ACK 重传次数。

### 方式一：调大 `netdev_max_backlog`

当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值，比如设置为 10000：

```
net.core.netdev_max_backlog = 10000
```

### 方式二：增大 TCP 半连接队列

增大 TCP 半连接队列，要同时调大下面这三个参数：
- 增大 `net.ipv4.tcp_max_syn_backlog`；
- 增大 `listen()` 函数中的 `backlog`；
- 增大 `net.core.somaxconn`。

### 方式三：开启 `net.ipv4.tcp_syncookies`

开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。
#### 具体过程：
- 当 `SYN` 队列满之后，后续服务器端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 **cookie** 值；
- 将 cookie 值放到第二次握手报文的“序列号”里，然后服务器端回第二次握手给客户端；
- 服务器端接收到客户端的应答报文时，服务器端会检查这个 ACK 包的合法性。如果合法，将该连接放入到 `Accept` 队列。
- 最后应用程序通过调用 `accept()` 接口，从 `Accept` 队列里取出的连接。

#### `net.ipv4.tcp_syncookies` 主要有三个取值：
- `0`：表示关闭该功能；
- `1`：表示仅当 SYN 半连接队列放不下时，再启用它；
- `2`：表示无条件开启功能。
那么在应对 SYN 攻击时，只需要设置为 `1` 即可。

### 方式四：减少 SYN+ACK 重传次数

SYN-ACK 报文的最大重传次数由 `tcp_synack_retries` 内核参数决定（默认值是 5 次），比如将 `tcp_synack_retries` 减少到 `2` 次：


---


## TCP 四次挥手的具体过程

- **客户端主动调用关闭连接的函数**，于是就会发送 FIN 报文，这个 FIN 报文代表客户端不会再发送数据了，进入 `FIN_WAIT_1` 状态；
- **服务器端收到 FIN 报文**，然后马上回复一个 ACK 确认报文，此时服务器端进入 `CLOSE_WAIT` 状态。
    - 在收到 FIN 报文的时候，TCP 协议栈会认为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，
    - 服务器端应用程序可以通过 `read` 调用来感知这个 FIN 包，这个 `EOF` 会被放在已排队等待的其他已接收的数据之后，所以必须要继续读取缓冲区已接收的数据；
- **接着，当服务器端** `read` **数据结束时**，最后自然会到达 `EOF`，接着 `read()` 就会返回 `0`。
    - **这时服务器端应用程序如果有数据要发送的话，就会先发送数据后才调用关闭连接的函数**，
    - **如果服务器端应用程序没有数据要发送的话，可以直接调用关闭连接的函数**，
    - 这时服务器端就会发一个 FIN 报文，这个 FIN 报文代表服务器不会再发送数据了，之后进入 `LAST_ACK` 状态；
- **客户端接收到服务器端的 FIN 包，并发送 ACK 确认包给服务器端**，此时客户端将进入 `TIME_WAIT` 状态；
- **服务器收到 ACK 确认包后**，就进入了最终的 `CLOSE` 状态；
- **客户端经过 2MSL（Maximum Segment Lifetime，最大报文存活时间） 时间之后，也进入** `**CLOSE**` **状态**：
	- - **确保服务器端成功接收到客户端发送的最终 ACK**
	    - 如果服务器端没有收到 ACK，会重新发送 FIN。
	    - `TIME_WAIT` 允许客户端重新发送 ACK 确保连接正确关闭。
	- **防止历史连接的旧报文影响新连接**
	    - 如果 TCP 连接立即关闭，旧的、延迟到达的报文可能会干扰新建立的连接。
	    - `2MSL` 确保旧报文在网络中消失后，新的 TCP 连接才会建立，避免冲突。

![[tcp_four_times_wave.webp]]



---


## 第二次挥手和第三次挥手能合并吗

当被动关闭方在 TCP 挥手过程中，**没有数据要发送** 并且 **开启了 TCP 延迟确认机制**，那么第二次和第三次挥手就会合并传输，这样就出现了 **三次挥手**。


### 延迟机制是什么
在 TCP 通信中，发送方每发送一个数据包，接收方都需要返回一个 ACK 确认。  
如果接收方 **每接收一个小数据包就立刻回复 ACK**，会导致：
- **ACK 报文过多，增加网络负载**（尤其是在小数据包传输场景下）。
- **CPU 处理 ACK 的开销增大**（每个 ACK 都需要占用 CPU 资源）。

**解决方案**：  
TCP 采用 **延迟确认（Delayed ACK）**，即：
- **暂缓发送 ACK**，等待 **一小段时间**（一般是 40ms-200ms）。
- 在这段时间内，如果**有数据要发送，就直接捎带 ACK 发送**，避免单独发送 ACK，提高网络效率。


### **延迟确认的触发条件**

接收方的 TCP 采用以下规则决定是否 **延迟发送 ACK**：
1. **如果收到的数据包可以立即传递给上层应用**（如应用调用了 `read()`），则立即发送 ACK。
2. **如果接收方有数据要发送**，就直接在数据包中捎带 ACK。
3. **如果接收方在 200ms（一般的默认值）内没有数据要发送**，就强制发送 ACK，避免超时导致的重传。

### **延迟确认的影响**
#### **优势**
- **减少 ACK 包的数量**，降低网络开销。
- **提高吞吐量**，特别是在大数据传输时，减少 CPU 处理 ACK 的负担。

### **劣势**
- **可能导致数据发送延迟**，影响实时性应用。

### **延迟确认如何影响 TCP 四次挥手？**

在 **TCP 断开连接（四次挥手）** 时，如果 **服务器端开启了延迟确认**，那么：
- 服务器端收到客户端的 `FIN` 之后，不会立即发送 `ACK`，而是**等一会儿再发送**。
- 如果此时 **服务器端没有数据要发送**，但等待时间还没到，`ACK` 仍会延迟发送。
- 这就导致 **第二次和第三次挥手的报文可能合并**，从而变成 **“三次挥手”**。


---


## 第三次挥手一直没发，会发生什么？

当主动方收到 ACK 报文后，会处于 `FIN_WAIT_2` 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。

- 这时，如果连接是用 `shutdown` 函数关闭的，连接可以一直处于 `FIN_WAIT_2` 状态，因为它可能还可以发送或接收数据。
- 但对于 `close` 函数关闭的彻底连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下连接的持续时长，默认值是 **60 秒**。


---


## 第二次和第三次挥手之间，主动断开的那端能干什么？

如果主动断开的一方，是**调用了** `shutdown` **函数关闭连接**，并且只选择了关闭发送能力且**没有关闭接收能力**的话，那么主动断开的一方在 **第二次和第三次挥手之间仍然可以接收数据**。
![[client_after_fin.webp]]



---


## 断开连接时客户端 FIN 包丢失，服务器的状态是什么？

当客户端（主动关闭方）调用 `close` 函数后，就会向服务器端发送 FIN 报文，试图与服务器端断开连接，此时客户端的连接进入到 `FIN_WAIT_1` 状态。

正常情况下，如果服务器能够及时收到客户端的 ACK，则会很快变为 `FIN_WAIT_2` 状态。

如果 **第一次挥手丢失**，那么客户端迟迟收不到服务器的 ACK 的话，也会触发超时重传机制，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

当客户端重传 FIN 报文的次数超过 `tcp_orphan_retries` 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，**那么客户端直接进入到** `close` **状态，而服务器端还是** `ESTABLISHED` **状态**。

举个例子，假设 `tcp_orphan_retries` 参数值为 `3`，当第一次挥手一直丢失时，发生的过程如下图：
![[lose_fin.webp]]



---


## 为什么四次挥手之后要等 2MSL？

**MSL（Maximum Segment Lifetime，报文最大生存时间）** 是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。由于 TCP 报文基于 IP 传输，而 IP 头中有一个 `TTL`（Time To Live，生存时间）字段，表示 IP 数据报可以经过的最大路由跳数。每经过一个路由器，TTL 值就会减少 1，当 TTL 变为 `0` 时，数据报就会被丢弃，同时发送 ICMP 报文通知源主机。

### **MSL 与 TTL 的关系**
- **MSL 的单位是时间，而 TTL 是经过的路由跳数**，所以 **MSL 应该大于等于 TTL 消耗为** `0` **的时间**，以确保报文已经被完全消除。
- TTL 的值一般是 `64`，Linux 将 `MSL` 设定为 `30` 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 `30` 秒，如果超过了，就认为报文已经消失在网络中。

### **为什么 TIME_WAIT 需要等 2 倍 MSL？**
- 网络中可能存在来自发送方的 **重复数据包**，当这些数据包被接收或丢弃后，必须等待 **一轮**，然后确保对方不会再收到影响。
- 如果被动关闭方没有收到断开连接的最终 `ACK`，它会 **超时重发 FIN 报文**。
- **2MSL 确保在 TCP 连接关闭后，所有旧报文都已经消失**，避免影响新的连接。

### **2MSL 机制的作用**

等待 **2MSL** 时长，确保已经离开 TCP 连接的报文 **不会影响新连接**。
- **若一个 MSL 内丢失 FIN**，那么该 FIN 可能在 `2MSL` 时间内重新抵达。
- **如果 FIN 在 2MSL 内未重新抵达，则认为连接完全关闭**，可以释放端口。

因此，`TIME_WAIT` 等待 2MSL 的时间 **相当于让所有旧报文失效一次**，保证新的连接不会受到干扰。


---

## 服务器端出现大量的 TIME_WAIT 的原因

### **问题：什么场景下服务器端会主动断开连接？**

- **场景 1**：HTTP 没有使用长连接
- **场景 2**：HTTP 长连接超时
- **场景 3**：HTTP 长连接的请求数量达到上限

### **场景 1：HTTP 没有使用长连接**
#### **HTTP Keep-Alive 机制**
在 HTTP/1.0 中，默认是短连接。如果浏览器想要启用 **Keep-Alive**，需要在 HTTP 请求的 `header` 中添加：
```
Connection: Keep-Alive
```
然后当服务器端收到请求并作出响应时，它也会在 `header` 里加上：
```
Connection: Keep-Alive
```
这样 TCP 连接就不会立即中断，而是保持连接。这样当客户端再次发送请求时，可以复用同一个 TCP 连接。

#### **HTTP/1.1 的默认行为**
从 **HTTP/1.1 开始，默认启用了 Keep-Alive**，现在大多数浏览器都默认使用 HTTP/1.1，因此 Keep-Alive 也默认是开启的。只要客户端和服务器端都没有主动关闭连接，那么 HTTP 长连接就会建立。
如果要关闭 **Keep-Alive**，则需要在 `HTTP header` 里加入：
```
Connection: close
```
这样服务器在响应后就会主动关闭连接，导致 `TIME_WAIT` 连接增多。

#### **谁来主动断开 HTTP 连接？**
根据 RFC 文档，**请求方和响应方都可以主动关闭 TCP 连接**。
但是，在大多数 **Web 服务器的实现** 中，无论客户端是否禁用了 `Keep-Alive`，**服务器通常会主动关闭 HTTP 连接**，这就是服务器上 **大量 TIME_WAIT 连接的原因**。


### **场景 2：HTTP 长连接超时**

**HTTP 长连接的特性**：

- 只要**任意一端没有主动断开连接**，则 TCP 连接就会持续保持。
    
- 可以在**同一个 TCP 连接**上收发多个 HTTP 请求/响应，避免 TCP 连接的频繁建立和释放。
    

#### **为什么长连接超时会导致 TIME_WAIT？**
如果客户端完成一个 HTTP 请求后，没有再发起新的请求，TCP 连接会**一直占用**，这是否会浪费资源？

**不会！**

为了避免资源浪费，**Web 服务器会设置一个超时参数**，指定 HTTP 长连接的**超时时间**。
例如，Nginx 提供 `keepalive_timeout` 参数。
```
keepalive_timeout 60;
```
- **如果客户端在 60 秒内没有新的 HTTP 请求，Nginx 就会主动关闭该连接**，从而产生大量 `TIME_WAIT` 连接。
- 可以调整该参数减少 `TIME_WAIT` 连接。


### **场景 3：HTTP 长连接的请求数量达到上限**

Web 服务器通常有参数**限制**每个 HTTP 长连接最多能处理的请求数量，当超过最大限制时，就会**主动关闭连接**。
例如，Nginx 提供 `keepalive_requests` 参数：
```
keepalive_requests 100;
```
这个参数的含义是：
- **每个 HTTP 长连接最多只能处理 100 次请求**。
- 达到 `100` 次后，**Nginx 会主动关闭连接**，导致 `TIME_WAIT` 连接增多。

#### **QPS 高的情况下可能导致大量 TIME_WAIT**
- **对于一般业务，默认值** `100` **次够用了。**
- **但是如果是高 QPS（每秒请求数）的场景，例如** `10000 QPS`、`30000 QPS`、`50000 QPS`，那么** `100` **这个阈值可能过低。**
- **解决方案**：可以**增大** `**keepalive_requests**`，减少服务器主动关闭连接的次数，减少 `TIME_WAIT` 连接。


## **总结**

服务器端出现大量 `TIME_WAIT` 状态的连接，主要是由于以下三种情况：
1. **HTTP 没有使用长连接**，服务器每次处理完请求后都会主动关闭连接。
2. **HTTP 长连接超时**，服务器在指定时间内未收到新的请求，则主动关闭连接。
3. **HTTP 长连接的请求数达到上限**，服务器为了控制资源消耗，在达到最大请求次数后主动关闭连接。

**优化建议**：
- **开启 HTTP 长连接（Keep-Alive）**，避免频繁创建 TCP 连接。
- 查看服务器网络状况，是否没有接收到客户端的信息（第二种场景）
- **增大** `keepalive_requests`，减少服务器主动关闭连接的频率。


---


## TCP 和 UDP 的区别

### **1. 连接方式**
- **TCP**：面向连接的传输层协议，传输数据前必须先建立连接。
- **UDP**：无连接协议，可以直接发送数据，无需建立连接。

### **2. 服务对象**
- **TCP**：一对一的点对点服务，即一个 TCP 连接只有两个端点。
- **UDP**：支持 **一对一**、**一对多**、**多对多** 等通信模式。

### **3. 可靠性**
- **TCP**：可靠传输，数据无丢失、不重复、不乱序，按序到达。
- **UDP**：尽最大努力交付，不保证可靠传输。如果需要可靠性，可以基于 UDP 实现，例如 **QUIC 协议**。

### **4. 拥塞控制和流量控制**
- **TCP**：有拥塞控制和流量控制机制，确保数据传输的安全性。
- **UDP**：没有拥塞控制，即使网络异常，UDP 也不会影响发送速率。

### **5. 首部开销**
- **TCP**：首部较长，最小 **20 字节**，如果使用了选项字段则可能更长。
- **UDP**：首部仅 **8 字节**，结构简单，传输开销小。

### **6. 传输方式**
- **TCP**：**流式传输（Stream）**，无边界，但保证顺序和可靠性。
- **UDP**：**数据报传输**，以 **数据包（Datagram）** 为单位发送，可能会丢包和乱序。

### **7. 适用场景**

|**协议**|**适用场景**|
|---|---|
|**TCP**|可靠传输，例如 HTTP、HTTPS、FTP、SSH、邮件传输等|
|**UDP**|低时延或对丢包不敏感的场景，如 DNS、视频流、VoIP、游戏、广播等|

### **8. 传输效率**
- **TCP**：由于需要建立连接、维护状态、流控、重传，效率较低。
- **UDP**：不需要连接，直接发送，传输效率高，适合实时应用。


### **总结**

| **对比项** | **TCP**               | **UDP**               |
| ------- | --------------------- | --------------------- |
| 是否面向连接  | 是                     | 否                     |
| 传输可靠性   | 可靠，保证不丢失、按序到达         | 尽力传输，不保证可靠性           |
| 传输方式    | **流式传输**              | **数据报传输**             |
| 拥塞控制    | 有                     | 无                     |
| 传输效率    | 较低                    | 高                     |
| 首部开销    | 20~60 字节              | 8 字节                  |
| 适用场景    | 需要高可靠性，如 HTTP、FTP、SSH | 低时延应用，如视频、VoIP、游戏、DNS |

**TCP 适用于对可靠性要求高的应用，而 UDP 适用于低时延、高吞吐的应用**


---


## 流式传输 和 数据报传输

**流式传输（Stream-Oriented Transmission）** 和 **数据报传输（Datagram-Oriented Transmission）** 是两种不同的通信方式，分别对应 **TCP** 和 **UDP**。

### **1. 流式传输（Stream-Oriented Transmission，TCP）**

**定义**：
- **数据以连续的字节流（Stream）形式传输，没有固定的消息边界**。
- **数据在传输时可能会被拆分或合并**，接收端需要根据应用协议来解析数据。

**特点**：
1. **无边界**：发送的数据可能会被 TCP 拆分成多个数据包，也可能多个小数据合并到一个数据包中，接收端需要自行处理数据的完整性。
2. **可靠性**：提供 **错误检测、丢包重传、流量控制、拥塞控制**，保证数据按序、无损地到达接收端。
3. **按序传输**：TCP 通过 **序列号** 确保数据按照发送顺序到达接收端。
4. **面向连接**：必须先建立连接（如 **三次握手**）才能通信，通信完成后需要 **四次挥手** 断开连接。
5. **适用于数据量大、需要可靠传输的场景**。

**适用场景**：
- HTTP/HTTPS（网页浏览）
- FTP（文件传输）
- SSH（远程终端）
- 邮件协议（SMTP、IMAP、POP3）

### **2. 数据报传输（Datagram-Oriented Transmission，UDP）**

**定义**：
- **数据以一个个独立的消息（Datagram）传输，每个数据包都是一个完整的独立单元，具有明确的边界**。
- **数据包之间相互独立，可能会丢失、重复、乱序**。

**特点**：

1. **有边界**：每个数据报都是一个完整的消息，接收方按照数据报的 **边界** 读取，不会合并或拆分。
2. **无可靠性保证**：UDP **不提供错误检测、丢包重传、流控、拥塞控制**，数据可能会丢失、重复或乱序到达接收方。
3. **无连接**：不需要建立和断开连接，直接发送数据即可。
4. **低延迟**：由于没有连接管理和重传机制，UDP 适用于对时延敏感的应用，如 **音视频、游戏、DNS** 等。

**适用场景**：
- 视频流（如 IPTV、直播）
- 语音通信（如 VoIP）
- 在线游戏（如 FPS、MOBA）
- DNS 解析
- 网络广播、组播

### **3. 主要区别总结**

|**对比项**|**流式传输（TCP）**|**数据报传输（UDP）**|
|---|---|---|
|**数据结构**|**字节流（Stream）**，数据是连续的|**数据报（Datagram）**，有固定的边界|
|**传输方式**|可靠传输，按序传输，数据可能被拆分或合并|无可靠性，数据报单独传输，可能丢失、乱序|
|**连接**|需要建立连接（三次握手），断开连接（四次挥手）|无连接，直接发送数据|
|**数据完整性**|需要应用层协议处理数据分段|每个数据报是完整的|
|**适用场景**|高可靠性应用，如 HTTP、FTP、SSH|低时延应用，如视频流、VoIP、游戏|


---


## TCP 为什么可靠传输
TCP 协议主要通过以下几个机制来保证传输可靠性：
- **连接管理**：TCP 通过 **三次握手** 建立连接，**四次挥手** 断开连接，保证了连接的可靠性。只有在连接建立成功后，数据才能被可靠地传输。
- **序列号**：TCP **对每个字节的数据进行编号**，使用序列号来保证数据的正确接收。
	- **防止数据丢失**：如果数据包丢失，接收方无法收到某个序列号的包，发送方可以重传该包。
	- **避免数据重复**：如果接收方收到相同序列号的数据，可以丢弃重复的包。
	- **保证数据有序**：按序列号顺序进行数据包组装，防止数据乱序。
	- **提高传输效率**：序列号结合 **累积 ACK** 机制，可以优化数据传输。
- **确认应答**：**接收方每次收到数据后，会返回 ACK 确认报文**。
	- **ACK 中包含已成功接收的序列号**，用于告诉发送方数据包已成功到达。
	- **超时机制**：如果发送方长时间未收到 ACK，则会触发重传机制。
- **超时重传**：用于应对数据包丢失或 ACK 丢失的情况。
	- 如果发送方在一定时间内没有收到 ACK，则会 **超时重传**。
	- **确认丢失的数据包** 后，向接收端重新发送丢失的数据包。
	- **接收方检测到重复数据包时，会丢弃重复包，并重新发送 ACK**。
- **流量控制**：由于<span style="color: blue;">接收方</span>的处理能力有限，TCP 采用流量控制机制，**保证数据不会发送过快，导致接收方处理不过来**。
	- **滑动窗口**（Sliding Window）：发送方根据接收方的 **窗口大小（Window Size）** 控制数据的发送速率。如果接收方缓冲区快满了，就会通知发送方减缓发送速度。
- **拥塞控制**：防止大量数据涌入网络，导致网络拥塞。
	- **慢启动（Slow Start）**：一开始发送速率较慢，逐步提升。
	- **拥塞避免（Congestion Avoidance）**：当拥塞窗口达到一定大小时，缓慢增加窗口值，避免网络拥塞。
	- **快重传（Fast Retransmit）**：如果发送方连续收到三个重复的 ACK，则立即重传丢失的数据包，而不等待超时。
	- **快恢复（Fast Recovery）**：当丢包发生时，不会直接回到慢启动阶段，而是减少窗口大小，继续传输。


---


## ## 怎么用 UDP 实现 HTTP？

UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输，在 HTTP/3 就用了 QUIC 协议。
- **连接迁移**：QUIC 支持在网络变化时快速迁移连接，例如从 WiFi 切换到移动数据网络，以保持连接的可靠性。
- **重传机制**：QUIC 使用重传机制来确保丢失的数据包能够被重新发送，从而提高数据传输的可靠性。
- **前向纠错（Forward Error Correction, FEC）**：QUIC 可以使用前向纠错技术，在接收端修复部分丢失的数据，降低重传的需求，提高可靠性和传输效率。
- **拥塞控制**：QUIC 内置了拥塞控制机制，可以根据网络状况动态调整数据传输速率，以避免网络拥塞和丢包，提高可靠性。


### QUIC协议
QUIC 协议是 **传输层协议**，虽然它运行在 UDP 之上，但它本质上是独立于 TCP 的新型传输层协议，而非应用层协议。它的设计目标是为 HTTP/3 提供低延迟和高效的可靠传输。
#### 端口号：
- QUIC 没有固定的端口号，可以在任意 UDP 端口上运行。
- **标准的 HTTP/3（基于 QUIC）默认使用 UDP 443 端口**，与 HTTPS（基于 TCP 的 TLS 443 端口）相同。
- 其他应用使用 QUIC 时，可以选择不同的端口，具体取决于实现和配置。

#### 前向纠错（Forward Error Correction, FEC）
前向纠错（FEC）是一种 **在数据发送时预先加入冗余信息，以便接收端能够在部分数据丢失或损坏的情况下自行恢复数据** 的技术。它是一种 **主动纠错** 方法，不依赖于重传，提高了数据传输的可靠性和效率，特别适用于 **高丢包率或高延迟的网络环境**。

##### FEC 的基本原理
FEC 通过在发送端增加额外的校验数据，使接收端能够**检测并纠正数据中的错误**，避免重新请求数据包。例如：
- 发送端在原始数据块的基础上 **计算额外的冗余数据（称为纠错码）** 并一同发送。
- 如果接收端丢失了一部分数据，但仍然收到了足够的冗余信息，它可以 **通过数学计算恢复丢失的数据**。
- 这样，接收端可以在 **无需向发送端请求重传** 的情况下自行修复数据，提高网络传输的效率。


---


## TCP 粘包怎么解决？
TCP 粘包问题主要是指不同的用户消息之间的边界不清晰。具体来说，它指的是 **多个独立的消息在 TCP 传输过程中被合并在一个数据包中，导致接收端无法正确拆分**。

一般有三种方式分包的方式：
- **固定长度的消息**；
- **特殊字符作为边界**；
- **自定义消息结构**。

### 固定长度的消息
这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。

但是这种方式灵活性不高，实际中很少用。

### 特殊字符作为边界
我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把它认为已经读完一个完整的消息。

HTTP 是一个非常好的例子（只是例子，头部和请求正文属于同一个用户消息）。
![[http_header.webp]]

HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。

有一点要注意，这个作为边界的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。

### 自定义消息结构
我们可以自定义一个消息结构，由包头和数据组成，其中包头是固定大小的，而且包头里有一个字段来说明紧跟其后的数据有多大。

比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。

```java
struct {
    u_int32_t message_length;
    char message_data[];
} message;
```

当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。


---


## TCP 的拥塞控制介绍

一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据；但是一直重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环不断地放大……

所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。

于是，就有了**拥塞控制**，控制的目的是**避免「发送方」的数据填满整个网络**。

为了在「发送方」调整所要发送数据的量，定义了一个叫做 **「拥塞窗口」** 的概念。

### 拥塞窗口（cwnd）

**拥塞窗口 cwnd** 是发送方维护的一个状态变量，它会根据**网络的拥塞程度动态变化**的。发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是 `swnd = min(cwnd, rwnd)`，也就是拥塞窗口和接收窗口中的最小值。

#### 拥塞窗口 cwnd 变化的规则：
- 如果网络中没有出现拥塞，**cwnd 就会增长**；
- 但如果网络中出现了拥塞，**cwnd 就减少**。

### 如何判断网络是否出现拥塞？
判断网络是否拥塞的方式很简单，**只要「发送方」没有在规定时间内接收到 ACK 应答报文，就会触发超时重传，认为网络出现了拥塞**。

### 拥塞控制的四大算法
TCP 拥塞控制主要包括四个算法：
- **慢启动（Slow Start）**
- **拥塞避免（Congestion Avoidance）**
- **拥塞发生（Congestion Occurrence）**
- **快速恢复（Fast Recovery）**

### **慢启动算法**
TCP 在刚建立连接完成后，首先会有一个**慢启动**的过程，这个慢启动的意思就是**一点一点的提高发送数据包的数量**，如果一上来就发送大量的数据，这不是给网络添堵吗？

![[slow_start.webp]]


#### **慢启动的规则**

记住一个核心原则：
- **当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1**。

#### **慢启动过程示例**
- 连接建立完成后，一开始初始化 `cwnd = 1`，表示可以传一个 MSS 大小的数据。
- 当收到 1 个 ACK 确认应答后，`cwnd` 增加 1，下一次可以发送 2 个。
- 当收到 2 个 ACK 确认应答后，`cwnd` 增加 2，下一次可以发送 4 个。
- 当 4 个 ACK 确认到来时，每个确认 `cwnd` 增加 1，4 个确认一共增加 4，下一次可以发送 8 个。

可以看出**慢启动算法的发送个数是指数性增长的**。

#### **慢启动的停止条件**
- 有一个叫做 **慢启动门限（ssthresh，Slow Start Threshold）** 的状态变量。
- 当 `cwnd < ssthresh` 时，使用慢启动算法。
- 当 `cwnd >= ssthresh` 时，就会使用 **拥塞避免算法**。

### **拥塞避免算法**
**当** `cwnd` **超过** `ssthresh` **时，就进入拥塞避免阶段。**

拥塞避免算法的规则是：
- **每当收到一个 ACK，cwnd 增加** `1/cwnd`。

![[congestion_avoidance.png]]


#### **拥塞避免过程示例**
- 假设 `ssthresh = 8`，那么当 8 个 ACK 确认到来时，每个确认 `cwnd` 增加 `1/8`，8 个 ACK 累计 `cwnd` 一共增加 1，于是下一次发送 9 个 MSS 大小的数据。
- 也就是说，**增长速率从指数增长变为线性增长**。

 **进入拥塞避免阶段后，TCP 继续增长，但增长速度比慢启动慢，减少对网络的压力。**

### **拥塞发生（Congestion Occurrence）**
如果网络持续增长，最终还是会出现丢包现象，这就意味着网络进入了**拥塞状态**。
此时，TCP 需要进行丢包处理，通常采用**重传机制**，然后进入**拥塞发生算法**，调整 `cwnd` 以减少数据发送量。

![[timeout_resend.webp]]

当发生**超时重传**时，TCP 进入**拥塞发生算法**，调整 `cwnd` 以减少数据发送量。
规则如下：
- `ssthresh` 设为 `cwnd / 2`；
- `cwnd` 重新初始化为 `1`（恢复初始值）。

此时，TCP 重新进入**慢启动阶段**，逐步提高发送速率。


### **快速恢复算法（Fast Recovery）**

当接收方发现**一个中间数据包丢失**，但仍然能够收到部分数据时，它会发送 **三次重复 ACK**，触发快速重传，而不是等待超时重传。

![[fast_resend_and_fast_recovery.webp]]


在进入快速恢复之前，调整如下：
- `cwnd = cwnd / 2`（窗口减半）；
- `ssthresh = cwnd`。

然后，进入**快速恢复算法**：
- `cwnd = ssthresh + 3`（因为已经收到 3 个 ACK 确认）；
- 立即重传丢失的数据包；
- 如果继续收到重复 ACK，则 `cwnd` 继续增加 1；
- 如果收到新的数据 ACK，则 `cwnd` 恢复到 `ssthresh`，并进入拥塞避免状态