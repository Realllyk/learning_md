
## 操作系统的内存管理
操作系统设计了虚拟内存，每个进程都有自己的独立的虚拟内存，我们所写的程序不会直接与物理内存打交道。

有了虚拟内存之后，它带来了这些好处：
1. **虚拟内存可以使得进程对运行内存超出物理内存大小**，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
2. **由于每个进程都有自己的页表，所以每个进程的虚拟内存空间都是相互独立的**。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
3. **页表里的页表项中除了存了物理地址之外，还有一些标志位的特性**，比如控制一页的读写权限，标记该页是否在内存等。在内存访问方面，操作系统提供了更好的安全性。

Linux 是通过对内存分页的方式来管理内存，**分页是把整个虚拟和物理内存空间切割成一段段固定大小的块**，这样的块连续并且大小是固定的内存空间，我们叫**页（Page）**。在 Linux 下，每一页的大小为 4KB。
虚拟地址与物理地址之间通过**页表**来映射，如下图：

![[memory_management.webp]]

页表是存储在内存里的，**内存管理单元（MMU）** 就做将虚拟内存地址转换成物理地址的工作。
而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。


---


## 页表

**分页是把整个虚拟和物理内存空间切割成一段段固定大小的块**，这样一个连续并且尺寸固定的内存空间，我们叫**页（Page）**。在 Linux 下，每一页的大小为 4KB。

虚拟地址与物理地址之间通过**页表**来映射。

![[memory_management.webp]]

<span style="color: blue;">页表是存储在内存里的</span>，**内存管理单元（MMU）** 就负责将虚拟内存地址转换成物理地址的工作。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

内存分页由于内存空间被预先划分好的块，也不会像内存分段一样，在段与段之间产生较大的间隙。**由于用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**

但是，分页的最小分配单位是页，即便程序不足一页大小，我们最小只能分配一页，所以会出现**内部碎片**。

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。
- **页号**：作为页表的索引。
- **页表**：存储物理页的基地址。
- **页内偏移**：用于计算具体的物理地址。

![[virtual_address_to_mac_address.webp]]
### 内存地址转换的步骤：
1. 把虚拟内存地址，切分成页号和偏移量；
2. 根据页号，从页表里查询对应的物理页号；
3. 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。


---


## 段式内存管理

虚拟地址也可以通过**段表**与物理地址进行映射的，分段机制会把程序的虚拟地址分成多个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址。

![[segment.png]]

如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为：
**段 3 基地址 7000 + 偏移量 500 = 7500**。


---


## 用户态内存布局

![[user_state_memory.webp]]

用户空间内存，从**低到高**分别是 6 种不同的内存段：
- **代码段**，包括二进制可执行代码；
- **数据段**，包括已初始化的静态变量和全局变量；
- **BSS 段**，包括未初始化的静态变量和全局变量；
- **堆**，包括动态分配的内存，从低地址开始向上增长；
- **文件映射段**，包括动态、共享内存等；
- **栈**，包括局部变量和函数调用的上下文等。栈的大小一般是 **8MB**，当然系统也提供了参数，以便我们自定义大小。

上图中的内存布局可以看到，代码段下面还有一段不可用的内存空间（灰色部分），这块区域称为**保留区**，主要是为了防止无效指针访问。通常 C 语言中无效的 `NULL` 指针就是指向这块区域，避免程序因 bug 访问无效地址导致崩溃。

在这 7 个内存段中，**堆和文件映射段**的内存是动态分配的。例如，使用 C 语言标准库的 `malloc()` 或 `mmap()`，就可以分别在堆和文件映射区动态分配内存。


---


## 堆和栈的区别？

- **分配方式**：堆是动态分配内存，由程序员手动申请和释放内存，通常用于存储动态数据结构和对象。栈是静态分配内存，由编译器自动分配和释放内存，用于存储函数的局部变量和函数调用信息。
- **内存管理**：堆需要程序员手动管理内存的分配和释放，如果管理不当可能会导致内存泄漏或内存溢出。栈由编译器自动管理，遵循**后进先出**的原则，变量的生命周期由其作用域决定，函数调用时分配内存，函数返回时回收内存。
- **大小和速度**：堆通常比栈大，内存空间较大，但动态分配和释放内存需要时间开销。栈大小有限，通常较小，但内存分配和释放速度较快，因为是由编译器自动管理。


---

## fork() 会复制哪些东西？
- `fork` 阶段会复制父进程的页表（虚拟内存）。
- `fork` 之后，如果发生了写时复制（Copy-On-Write，COW），就会复制物理内存。

### 写时复制（Copy-On-Write，COW）机制

![[copy_on_write.webp]]

在 `fork()` 之后，子进程共享父进程的物理内存数据，这样能够**节约物理内存资源**，页表对应的页表项的属性会标记该物理内存的权限为**只读**。

但是，当父进程或者子进程尝试向这个内存发起写操作时，CPU 就会触发**写保护中断**，这个写保护中断是由于违反权限导致的。然后，操作系统会在「写保护中断处理函数」里进行**物理内存的复制**，并重新设置其内存映射关系，将父子进程的内存读写权限设为**可读写**，最后才会对内存进行写操作，这个过程被称为**写时复制（Copy On Write, COW）**。

写时复制的核心思想是：**只有在发生写操作时，操作系统才会去复制物理内存**。这样可以防止 `fork` 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题，提高 `fork` 的性能。


---
## malloc 1KB 和 1MB 有什么区别？

malloc() 源码里默认定义了一个阈值：
- 如果用户分配的内存小于 128 KB，则通过 `brk()` 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 `mmap()` 申请内存；

注意，不同的 glibc 版本定义的阈值是不同的。


---

## 介绍一下 `brk` 和 `mmap`

实际上，malloc() 并不是系统调用，而是 C 库的函数，用于动态分配内存。

malloc 申请内存时，会有两种方式向操作系统申请堆内存：
- **方式一**：通过 `brk()` 系统调用从堆分配内存；
- **方式二**：通过 `mmap()` 系统调用在文件映射区域分配内存；

![[brk.webp]]

方式一的实现方式很简单，就是通过 `brk()` 函数将「堆顶」指针向高地址移动，获得新的内存空间。

![[mmap.webp]]

方式二通过 `mmap()` 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。


---


## 操作系统内存不足的时候会发生什么？

应用程序通过 `malloc` 函数申请内存时，实际上申请的是**虚拟内存**，此时并不会分配物理内存。

当应用程序读取了这块虚拟内存，CPU 就会访问该虚拟内存。这时如果发现该虚拟内存没有映射到物理内存，CPU 就会产生<span style="color: blue;">缺页中断</span>，进程会从用户态切换到内核态，并将缺页中断交给内核的 `Page Fault Handler`（缺页中断函数）处理。

**缺页中断处理流程**：
- 如果有空闲的物理内存，操作系统会直接分配，并建立虚拟内存与物理内存之间的映射关系。
- 如果没有空闲物理内存，操作系统会执行<span style="color: blue;">回收内存</span>，主要方式包括：
    - **后台内存回收（kswapd）**：内核线程 `kswapd` 在物理内存紧张时回收内存，不会阻塞应用进程，是<span style="color: blue;">异步</span>的。
    - **直接内存回收（direct reclaim）**：如果 `kswapd` 无法满足需求，系统会阻塞进程并进行内存回收，是<span style="color: blue;">同步</span>的。
- 如果回收仍无法满足内存申请，系统将触发<span style="color: blue;"> OOM（Out Of Memory）机制</span>，杀死占用内存过多的进程。OOM Kiiler机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以释放内存资源，如果物理内存依然不足，OOM Killer会继续占用杀死物理内存较高的进程，直到释放足够的位置/


![[free_memory.webp]]

### 可被回收的内存
操作系统在回收内存时，主要回收两类内存：
- **文件页（File-backed Page）**：磁盘缓存的数据、文件缓存等，可直接释放。
    - 回收**干净页**的方式是**直接释放内存**。
    - 回收**脏页**的方式是**先写回磁盘后再释放内存**。
- **匿名页（Anonymous Page）**：这部分内存没有实际载体，如堆、栈数据，不能直接释放。
    - 其回收方式是通过 **Linux 的 Swap 机制**，先写入磁盘，再释放内存。

内存回收基于 **LRU（Least Recently Used）算法**，维护 `active_list`（活跃页）和 `inactive_list`（非活跃页），优先回收**不常访问的内存页**。
### LRU 回收机制
- `active_list`：活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；
链表越接近尾部，表示页越不常访问。在回收内存时，系统会根据活跃程度，优先回收不活跃的内存。


---

## 页面置换有哪些算法？

当出现**缺页异常**，需要从磁盘调入新页面，而物理内存已满时，就必须选择一个**物理页**置换出去。
常见的页面置换算法有：
- **最佳页面置换算法（OPT）**
- **先进先出置换算法（FIFO）**
- **最近最久未使用的置换算法（LRU）**
- **时钟页面置换算法（Clock）**
- **最不常用置换算法（LFU）**

### 1. 最佳页面置换算法（OPT）

该算法的思路是**置换未来最长时间不访问的页面**。但由于无法预知未来，OPT 只能用来衡量其他算法的效率。
![[OPT.webp]]

### 2. 先进先出置换算法（FIFO）

选择**驻留时间最长的页面**进行置换，适合简单的系统，但可能导致**Belady 异常**（增加页面数反而增加缺页次数）。
![[FIFO.webp]]
### 3. 最近最久未使用（LRU）

选择**最长时间未被访问的页面**进行置换，假设历史访问模式能代表未来，但维护链表需要较高的开销。

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，**需要在内存中维护一个所有页面的链表**，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须更新**整个链表**。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，**实际应用中比较少使用**。
![[LRU.webp]]

### 4. 时钟置换算法（Clock）
Clock 算法是**LRU 的近似实现**，使用一个循环链表和访问位，访问位为 0 的页面优先被置换。
- 所有的页面存储在**环形链表**中，一个表针指向最老的页面。
- 当发生缺页中断时，算法会首先检查表针指向的页面：
    - 如果其访问位为 `0`，则淘汰该页面，并将新页面插入该位置，随后表针向前移动一个位置；
    - 如果其访问位为 `1`，则清除访问位，并将表针向前移动一个位置，重复该过程，直到找到访问位为 `0` 的页面。
![[Clock.webp]]

### 5. 最不常用置换算法（LFU）

选择**访问次数最少的页面**进行置换，但可能会误淘汰新近刚刚开始频繁访问的页面。

它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就**累加 1**。在发生缺页中断时，淘汰计数器值最小的那个页面。

看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。

要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，**效率不高**。

但还有个问题，LFU 算法没考虑**频率时间问题**，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面并没有这些页面访问的次数高，在发生缺页中断时，就会可能**误伤当前刚开始频繁访问，但访问记录还不高的页面**。

那这个问题的解决办法还是有的，可以**定期减少访问的次数**，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就是说，**随着时间的流逝，以前的高访问次数的页面会慢慢减少，相当于加入了被置换的概率**。


---


## 内存分配方法概述

操作系统在为进程分配内存时，通常会将内存划分为**空闲区（Free List）**和**已分配区**。当有新进程需要内存时，系统会在空闲区中寻找一块合适的内存进行分配。

常见的内存分配算法有：
### 1. **First Fit（首次适应）**
- 从头开始遍历空闲区，找到**第一个**能满足要求的空闲块就分配。
- 分配速度快，但可能会产生大量小碎片（即前面小空闲块无法再被利用）。

### 2. **Best Fit（最佳适应）**
- 遍历所有空闲块，找到**最小的足够大的**空闲块来分配。
- 目标是**最少浪费空间**，但会产生很多小碎片（因为留下的剩余部分太小）。

### 3. **Worst Fit（最差适应）**
- 遍历所有空闲块，找到**最大的空闲块**来分配。
- 理念是：用最大的空闲块，可以保留较大的剩余部分，可能更有用。
- 缺点：容易把大块切成许多没用的小块，造成更严重的外部碎片。

### 4. **Next Fit（下次适应）**
- 类似 First Fit，但不是从头开始查找，而是从上一次查找结束的位置继续。
- 能减少前段的碎片利用压力，但不一定比 First Fit 效果更好。