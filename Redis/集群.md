
## Redis主从同步中的增量和完全同步怎么实现？

### 完全同步

完全同步发生在以下几种情况：
- **初次同步**：当一个从服务器（slave）首次连接到主服务器（master）时，会进行一次完全同步。
- **从服务器数据丢失**：如果从服务器数据由于某种原因（如断电）丢失，它会请求进行完全同步。
- **主服务器数据发生变化**：如果从服务器长时间与主服务器不同步，导致数据差异过大，也可能触发完全同步。

主从服务器间的第一次同步的过程可分为三个阶段：
1. 第一阶段是建立链接，协商同步；
2. 第二阶段是主服务器同步数据给从服务器；
3. 第三阶段是主服务器发送写操作命令给从服务器。

![[full_sync.webp]]

## 实现过程：

1. **从服务器发送PSYNC命令**：从服务器向主服务器发送 `PSYNC` 命令，请求同步数据。（**主从服务器之间建立的是TCP连接**，该连接用于数据同步和命令传输）
2. **主服务器生成RDB快照**：接收到 `PSYNC` 命令后，如果需要进行完整同步，主服务器会保存当前数据集的状态到一个临时文件，这个过程称为RDB（Redis Database）快照。
3. **传输RDB文件**：主服务器将生成的RDB文件发送给从服务器。
4. **从服务器接收并应用RDB文件**：从服务器接收RDB文件后，会清空当前的数据集，并载入RDB文件中的数据。
5. **主服务器记录写命令**：在RDB文件生成和传输期间，主服务器会记录所有接收到的写命令到 `replication backlog buffer`。
6. **传输写命令**：一旦RDB文件传输完成，主服务器会将 `replication backlog buffer` 中的命令发送给从服务器，从服务器会执行这些命令，以保证数据的一致性。


### 增量同步

增量同步允许从服务器从断点处继续同步，而不是每次都进行完全同步。它基于 `PSYNC` 命令，使用了运行ID（run ID）和复制偏移量（offset）的概念。

#### 主要有三个步骤：
1. 从服务器在恢复网络后，会发送 `PSYNC` 命令给主服务器，此时的 `PSYNC` 命令里的 offset 参数不为 -1；
2. 主服务器收到该命令后，然后用 `CONTINUE` 响应告知从服务器接下来采用增量复制的方式同步数据；
3. 然后主服务器将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。

![[increment_sync.webp]]


#### 那么关键的问题来了，主服务器是如何知道需要哪些增量数据发送给从服务器呢？

答案藏在这两个地方：
- `repl_backlog_buffer`，是一个环形缓冲区，用于主从服务器断连后，从中找到差异的数据；
- `replication offset`，标记上面环形缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 `master_repl_offset` 来记录自己「写」到的位置，从服务器使用 `slave_repl_offset` 来记录自己「读」到的位置。

#### 那 `repl_backlog_buffer` 缓冲区是什么时候写入的呢？
在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入 `repl_backlog_buffer` 缓冲区里，因此这个缓冲区里会存着最近传播的写命令。
当网络断开后，从服务器重新连接主服务器时，从服务器会通过 `PSYNC` 命令将自己的复制偏移量 `slave_repl_offset` 发送给主服务器，主服务器根据自己的 `master_repl_offset` 和 `slave_repl_offset` 之间的差距，然后决定从哪个位置开始发送数据给从服务器。
- **如果判断出从服务器要读取的数据还在** `repl_backlog_buffer` **缓冲区里**，那么主服务器将采用增量同步方式；
- **如果判断出从服务器要读取的数据已经不在** `repl_backlog_buffer` **缓冲区里**，那么主服务器将采用完全同步方式。

#### repl_backlog_buffer 需要多大？
`repl_backlog_buffer` 的默认大小是 1M，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。因此，如果主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。
如果网络恢复时，从服务器想读的数据已经被覆盖，主服务器就会采用完全同步，这个方式比增量同步的性能损耗要大很多。

因此，**为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整** `repl_backlog_buffer` **缓冲区大小，尽可能地大一些**，减少出现从服务器需要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。



---


## Redis 主从和集群可以保证数据一致性吗？
Redis 主从和集群在 CAP 理论中都属于 AP 模型，即在面临网络分区时选择保证可用性和分区容忍性，而牺牲了一致性。这意味着在网络分区的情况下，Redis 主从复制和集群可以继续提供服务并保持可用，但可能会出现部分节点之间的数据不一致。


---


### CAP 理论简介

CAP 理论是 Eric Brewer 在 2000 年提出的分布式系统理论，指出分布式系统无法同时满足以下三个特性：
1. **一致性（Consistency, C）**：所有节点访问同一份最新的数据。
2. **可用性（Availability, A）**：每个请求都能获得响应（无论数据是否是最新的）
	1. 每个非故障节点都必须对请求作出响应，而不会无限期地等待数据一致性恢复。
	2. 读请求和写请求都能够被处理，即使返回的数据可能不是最新的。
3. **分区容忍性（Partition Tolerance, P）**：系统在部分网络分区的情况下仍能继续运行。
	1. 在分布式系统中，网络分区是不可避免的，例如数据中心之间的连接中断、节点之间的网络延迟等。如果一个系统具有分区容忍性，即使某些节点之间无法直接通信，它仍然能够保证部分可用性，而不会完全崩溃。

由于网络分区（P）在分布式环境中是无法避免的，因此分布式系统只能在 C 和 A 之间做权衡。Redis 选择了 AP 模型，即牺牲强一致性来保证高可用性。



---


### 哨兵机制（Sentinel）

在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。

如果要恢复服务，需要人工介入，选择一个从节点切换为主节点，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。

Redis 在 2.8 版本以后提供的 **哨兵（Sentinel）机制**，它的作用是实现 **主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选择一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵其实是一个运行在特殊模式下的 Redis 进程，因此它也是一个节点。它主要负责三件事：

1. **监控**：持续检查主节点和从节点的健康状态；
2. **选主**：当主节点故障时，从现有从节点中选出新的主节点；
3. **通知**：将新的主节点信息通知给其他从节点和客户端，以完成故障转移。

![[Sentinel_worflow.webp]]


---


## 哨兵机制的选主节点算法
哨兵机制的选主节点算法包含以下步骤：

1. **故障节点主观下线**：Sentinel 节点会定期向所有 Redis 节点发送心跳包检测健康状态。如果主节点在 `down-after-milliseconds` 时间内无响应，Sentinel 认为该节点 **主观下线**。
   ![[主观下线.webp]]
2. **故障节点客观下线**：单个 Sentinel 不能决定主节点完全故障。Sentinel 需要与其他 Sentinel 协调，当超过 `quorum` 数量的 Sentinel 认为主节点故障，才会将其标记为 **客观下线**。
   ![[客观下线.png]]
3. **Sentinel 选举 Leader**：
    - 需要从 Sentinel 集群中选出一个 Leader。
    - 每个 Sentinel 节点都可以请求成为 Leader，其他 Sentinel 会投票。
    - 若某个 Sentinel 票数达到 quorum 或 (Sentinel 节点数 / 2 + 1) 的最大值，该 Sentinel 被选为 Leader，否则重新选举。
      ![[哨兵leader.webp]]
4. **Sentinel Leader 决定新主节点**：
   当 Sentinel 集群选举出 Sentinel Leader 后，由 Sentinel Leader 从 Redis 从节点中选择一个 Redis 节点作为主节点：
	1. 过滤故障的节点；
	2. 选择优先级 `slave-priority` 最大的从节点作为主节点，如果不存在则继续；
	3. 选择复制偏移量（数据丢失量）的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步，最大偏移量的从节点作为主节点，如不存在则继续；
	4. 选择 `runid`（Redis 每次启动时生成的随机 `runid` 作为 Redis 的标识），最小的从节点作为主节点。
    

这一机制确保了 Redis 集群在主节点故障后，能够自动选举新的主节点，减少人工干预，提高系统可用性。

![[选举主节点.webp]]

这一机制确保了 Redis 集群在主节点故障后，能够自动选举新的主节点，减少人工干预，提高系统可用性。


---


## Redis集群的模式了解吗 优缺点了解吗

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**（Redis Cluster）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：

1. 根据键值对的 key，按照 CRC16 算法计算出一个 16 bit 的值。
2. 再用 16bit 值对 16384 取模，得出 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上呢？有两种方案：

### **平均分配**
在使用 `cluster create` 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。例如集群中有 9 个节点，则每个节点上的哈希槽个数为 `16384 / 9`。

### **手动分配**
可以使用 `cluster meet` 命令手动建立节点间连接，组成集群，再使用 `cluster addslots` 命令，指定每个节点上的哈希槽个数。

为了方便你的理解，我通过一张图来解释数据、哈希槽，以及节点三者的映射分布关系。

![[redis_group_slut.webp]]

上图中的切片集群一共有 2 个节点，假设有 4 个哈希槽（Slot 0~Slot 3）时，我们就可以通过命令手动分配哈希槽，比如节点 1 保存哈希槽 0 和 1，节点 2 保存哈希槽 2 和 3。

```c
redis-cli -h 192.168.1.10 -p 6379 cluster addslots 0,1
redis-cli -h 192.168.1.11 -p 6379 cluster addslots 2,3
```

然后在集群运行的过程中，key1 和 key2 计算其 CRC16 值后，对哈希槽总个数 4 进行取模，再根据各自的模数结果，就可以被映射到哈希槽 1（对应节点 1）和 哈希槽 2（对应节点 2）。

需要注意的是，在手动分配哈希槽时，**需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作**。


## Redis 集群模式优点/缺点

### **优点：**

- **高可用性**：Redis 集群最主要的优点是提供了高可用性，节点之间采用主从复制机制，可以保证数据的持久性和容错能力，哪怕其中一个节点挂掉，整个集群还可以继续工作。
- **高性能**：Redis 集群采用分片技术，将数据分割到多个节点，从而提高读写性能。当业务访问量大到单机 Redis 无法满足时，可以通过添加节点来增加集群的吞吐量。
- **扩展性好**：Redis 集群的扩展性非常好，可以根据实际需求动态增加或减少节点，从而实现可扩展性。集群模式中的某些节点还可以作为代理节点，自动转发请求，增加数据模式的灵活度和可定制性。

### **缺点：**

- **部署和维护较复杂**：Redis 集群的部署和维护需要考虑到分片规则、节点的布置、主从配置以及故障处理等多个方面，需要较强的技术支持，增加了日常处理的复杂性和成本。
- **集群同步问题**：当某些节点失败或者网络故障时，集群中数据同步的问题也会出现。数据同步的复杂度和工作量随着节点的增加而增加，同时也会导致一定的读写延迟。
- **数据分片限制**：Redis 集群的数据分片也会限制功能的实现，如在一个 key 上修改较多次，可能会因为该 key 所在的节点位置变化而失败。此外，某些数据分布存储到各个节点，某些操作不能跨节点实现，不同节点之间的一些操作需要额外计算。