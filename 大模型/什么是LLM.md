### 💬 简单说法（面试时可以直接用）：
> LLM，全称是 Large Language Model，是一种使用大量文本数据训练出来的深度学习模型，能够理解人类语言，并生成语言。像我们常见的 ChatGPT、文心一言、通义千问，背后都是 LLM。
> 
> 它的核心就是：学会了语言的“规律”，可以做翻译、写代码、总结文档、对话问答等等。


### 📌 技术补充（如果面试官追问）：
- 它的底层是基于 Transformer 架构（Google 2017年提出的模型结构），非常适合处理长文本。
- 训练数据是海量的文本，模型参数可以达到百亿甚至千亿规模。
- LLM 的目标是预测下一个词（Next Token Prediction），通过这个过程它能逐渐学会语言的语法、逻辑和知识。

### 💡 Java 后端相关怎么说（加点关联）：
> 作为 Java 后端开发者，我们可能会跟 LLM 有两方面的结合：
> 1. **调用 LLM API**：比如用 Java 去调用 OpenAI、阿里通义的 API，帮产品加上智能问答、代码生成、自动摘要等能力。
> 2. **做中间层服务**：比如用 SpringBoot 构建一个微服务，让前端、移动端通过我们这个服务来使用 LLM，处理上下文、做缓存、限流、权限控制等。